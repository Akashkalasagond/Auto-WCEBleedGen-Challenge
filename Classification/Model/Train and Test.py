# -*- coding: utf-8 -*-
'''Train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NcEQ4AYXAuyDBVPScWmfjxFpnu9zSOsT
'''
---
---
# **Auto WCEBleedGen Competetion**
---
---

### **Bleeding / Non-Bleeding**

 #**The main goal of this challenge was to create a classification and detection model that could differentiate between bleeding and non-bleeding frames in wireless capsule endoscopy (WCE) images.**
--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#Importing all the Required Librarires

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from sklearn.model_selection import train_test_split

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, BatchNormalization
from keras.layers import Activation, Dropout, Flatten, Dense
from keras.applications import MobileNetV2
from keras.optimizers import Adam
from keras.metrics import Accuracy, Recall, Precision
from keras.layers import Dense, GlobalAveragePooling2D
from keras.callbacks import ModelCheckpoint, CSVLogger
from keras.regularizers import l2
from keras.applications import InceptionV3
import os
import cv2
from PIL import Image
import numpy as np

--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#Obtaining the Data shape and Label
image_directory = '/content/drive/MyDrive/final/WCEBleedGen/'

# Define the image size
SIZE = 224

# Initialize lists to store the dataset and labels
dataset = []
labels = []

# Function to read and preprocess images
def process_images(image_dir, label_value):
    for image_name in os.listdir(image_dir):
        if image_name.endswith('.png'):
            image_path = os.path.join(image_dir, image_name)
            try:
                image = cv2.imread(image_path)
                if image is not None:
                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                    image = cv2.resize(image, (SIZE, SIZE))
                    dataset.append(image)
                    labels.append(label_value)
                else:
                    print(f"Unable to load image: {image_path}")
            except Exception as e:
                print(f"Error processing {image_path}: {str(e)}")

# Process bleeding images
bleeding_directory = os.path.join(image_directory, 'bleeding/images')
process_images(bleeding_directory, label_value=1)

# Process non-bleeding images
non_bleeding_directory = os.path.join(image_directory, 'non-bleeding/images')
process_images(non_bleeding_directory, label_value=0)

# Convert dataset and labels to numpy arrays
dataset = np.array(dataset)
labels = np.array(labels)

# Print dataset and label shapes for verification
print('Dataset shape:', dataset.shape)
print('Label shape:', labels.shape)

"""**Random image from the dataset and its label**"""

import random
import matplotlib.pyplot as plt

# Generate a random image number
image_number = random.randint(0, len(dataset) - 1)

# Display the image and its label
plt.imshow(dataset[image_number])
plt.title("Label for this image is: " + str(labels[image_number]))  # Use 'labels' instead of 'label'
plt.show()

--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#Using DenseNet 121 Architecture to Extract Features
import os
import cv2
import numpy as np
from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.models import Model
from tensorflow.keras.layers import GlobalAveragePooling2D
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.densenet import preprocess_input
from tqdm import tqdm

# Define the image directories
image_directory = '/content/drive/MyDrive/final/WCEBleedGen/'
output_directory = '/content/drive/MyDrive/final/extracted_features/'

# Define the image size
SIZE = (224, 224)

# Create output directory if it doesn't exist
os.makedirs(output_directory, exist_ok=True)

# Load the DenseNet-121 model with pre-trained weights
base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Remove the top classification layers
x = base_model.output
x = GlobalAveragePooling2D()(x)

# Create a model for feature extraction
model = Model(inputs=base_model.input, outputs=x)

# Function to extract features from an image
def extract_features(image_path):
    img = image.load_img(image_path, target_size=SIZE)
    img = image.img_to_array(img)
    img = np.expand_dims(img, axis=0)
    img = preprocess_input(img)
    features = model.predict(img)
    return features

# Initialize lists to store features and labels
features_list = []
labels_list = []

# Process bleeding images
bleeding_directory = os.path.join(image_directory, 'bleeding/images')

for image_name in tqdm(os.listdir(bleeding_directory)):
    if image_name.endswith('.png'):
        image_path = os.path.join(bleeding_directory, image_name)
        features = extract_features(image_path)
        features_list.append(features)
        labels_list.append(1)  # Label 1 for bleeding

# Process non-bleeding images
non_bleeding_directory = os.path.join(image_directory, 'non-bleeding/images')

for image_name in tqdm(os.listdir(non_bleeding_directory)):
    if image_name.endswith('.png'):
        image_path = os.path.join(non_bleeding_directory, image_name)
        features = extract_features(image_path)
        features_list.append(features)
        labels_list.append(0)  # Label 0 for non-bleeding

# Convert lists to NumPy arrays
features_array = np.vstack(features_list)
labels_array = np.array(labels_list)

# Save the extracted features and labels in the "extracted_features" folder
np.save(os.path.join(output_directory, 'features.npy'), features_array)
np.save(os.path.join(output_directory, 'labels.npy'), labels_array)

print("Feature extraction and label saving completed.")

--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#CNN2d Model is being used to train the model.
import os
import numpy as np
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras.utils import to_categorical

# Load your extracted features (2618, 1, 1024)
features_array = np.load('/content/drive/MyDrive/final/extracted_features/features.npy')
labels_array = np.load('/content/drive/MyDrive/final/extracted_features/labels.npy')

# Reshape the features into (2618, 32, 32, 1)
features_array_2d = features_array.reshape((2618, 32, 32, 1))

# Split the data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(
    features_array_2d, labels_array, test_size=0.2, random_state=42)

# Convert labels to one-hot encoding
y_train = to_categorical(y_train)
y_val = to_categorical(y_val)

# Define the 2D CNN model
model = Sequential([s
    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 1)),
    MaxPooling2D(pool_size=(2, 2)),
    Flatten(),
    Dense(64, activation='relu'),
    Dropout(0.5),
    Dense(len(np.unique(labels_array)), activation='softmax')
])

# Compile the model
model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val))

# Evaluate the model
loss, accuracy = model.evaluate(X_val, y_val)
print(f"Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy:.4f}")

#Plot training & Validation loss values
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper right')

# Plot training & validation accuracy values
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'], loc='lower right')

plt.tight_layout()
plt.show()


--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#Required Metric Evaluation
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve, auc
import matplotlib.pyplot as plt

# Load your model and saved weights
model = Sequential([
    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 1)),
    MaxPooling2D(pool_size=(2, 2)),
    Flatten(),
    Dense(64, activation='relu'),
    Dropout(0.5),
    Dense(len(np.unique(labels_array)), activation='softmax')
])

model.load_weights('/content/drive/MyDrive/CNN2d.h5')  # Load your trained weights

# Predict on the validation data
y_pred = model.predict(X_val)

# Convert predicted probabilities to class labels (0 or 1)
y_pred_labels = np.argmax(y_pred, axis=1)
y_true_labels = np.argmax(y_val, axis=1)

# Calculate accuracy
accuracy = accuracy_score(y_true_labels, y_pred_labels)

# Calculate precision, recall, and F1 score
precision = precision_score(y_true_labels, y_pred_labels)
recall = recall_score(y_true_labels, y_pred_labels)
f1 = f1_score(y_true_labels, y_pred_labels)

# Calculate the confusion matrix
confusion = confusion_matrix(y_true_labels, y_pred_labels)

# Calculate ROC-AUC score and plot ROC curve
roc_auc = roc_auc_score(y_true_labels, y_pred_labels)
fpr, tpr, thresholds = roc_curve(y_true_labels, y_pred_labels)
roc_auc = auc(fpr, tpr)

# Print the metrics
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall (Sensitivity): {recall:.4f}")
print(f"F1 Score: {f1:.4f}")
print("Confusion Matrix:")
print(confusion)
print(f"ROC AUC Score: {roc_auc:.4f}")


--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#Confusion Matrix
import numpy as np
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Predict on the validation data
y_pred = model.predict(X_val)

# Convert predicted probabilities to class labels (0 or 1)
y_pred_labels = np.argmax(y_pred, axis=1)
y_true_labels = np.argmax(y_val, axis=1)

# Calculate the confusion matrix
confusion = confusion_matrix(y_true_labels, y_pred_labels)

# Plot the confusion matrix as a heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=["Non-Bleeding", "Bleeding"],
            yticklabels=["Non-Bleeding", "Bleeding"])
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.show()


--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#ROC AOC Curve
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()


--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#Kappa Score
from sklearn.metrics import cohen_kappa_score
# Calculate Cohen's Kappa
kappa = cohen_kappa_score(y_true_labels, y_pred_labels)

# Print the Kappa score
print(f"Cohen's Kappa Score: {kappa:.4f}")


--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#Specificity
TN, FP, FN, TP = confusion.ravel()

# Calculate Specificity
specificity = TN / (TN + FP)

# Print the Specificity
print(f"Specificity: {specificity:.4f}")


--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#Model Saved (1.53mb)
model.save('CNN2d.h5')

--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#Using the saved model (CNN2d.h5), accurately predicting the image's label of Test Dataset 1 and saving it to the test_dataset_1_Predictions.xlsx
import os
import cv2
import numpy as np
from tensorflow.keras.models import load_model
import pandas as pd

# Load the saved model
model = load_model('/content/drive/MyDrive/CNN2d.h5')

# Define the path to your test dataset directory
test_dataset_dir = '/content/drive/MyDrive/test_dataset/Test Dataset 1'

# List all image files in the test dataset directory
test_image_files = [f for f in os.listdir(test_dataset_dir) if f.endswith('.png')]

# Initialize lists to store image names and predicted labels
image_names = []
predicted_labels = []

# Iterate over the test images, convert to grayscale, resize, make predictions, and store results
for image_file in test_image_files:
    # Load and preprocess the test image
    image_path = os.path.join(test_dataset_dir, image_file)
    img = cv2.imread(image_path)

    if img is not None:
        # Convert the image to grayscale
        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # Resize the image to 32x32 pixels
        img_gray = cv2.resize(img_gray, (32, 32))

        # Reshape to (32, 32, 1)
        img_gray = img_gray.reshape(32, 32, 1)

        # Make a prediction using the loaded model
        prediction = model.predict(np.expand_dims(img_gray, axis=0))

        # Determine the predicted label by selecting the class with the highest probability
        predicted_label = np.argmax(prediction, axis=1)

        # Map the class index to the corresponding label (e.g., 0 for non-bleeding, 1 for bleeding)
        if predicted_label == 0:
            label = "non-bleeding"
        else:
            label = "bleeding"

        # Append image name and predicted label to the lists
        image_names.append(image_file)
        predicted_labels.append(label)
    else:
        print(f"Image: {image_file}, Shape: Unable to read the image")

# Create a DataFrame to store the results
df = pd.DataFrame({'Image Name': image_names, 'Predicted Label': predicted_labels})

# Save the DataFrame to an Excel file
df.to_excel('/content/drive/MyDrive/predictions.xlsx', index=False)

print("Predictions saved to predictions.xlsx")

--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#Using the saved model (CNN2d.h5), accurately predicting the image's label of Test Dataset 2 and saving it to the test_dataset_2_Predictions.xlsx
import os
import cv2
import numpy as np
from tensorflow.keras.models import load_model
import pandas as pd

# Load the saved model
model = load_model('/content/drive/MyDrive/CNN2d.h5')

# Define the path to your test dataset directory
test_dataset_dir = '/content/drive/MyDrive/test_dataset/Test Dataset 2'

# List all image files in the test dataset directory
test_image_files = [f for f in os.listdir(test_dataset_dir) if f.endswith('.png')]

# Initialize lists to store image names and predicted labels
image_names = []
predicted_labels = []

# Iterate over the test images, convert to grayscale, resize, make predictions, and store results
for image_file in test_image_files:
    # Load and preprocess the test image
    image_path = os.path.join(test_dataset_dir, image_file)
    img = cv2.imread(image_path)

    if img is not None:
        # Convert the image to grayscale
        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # Resize the image to 32x32 pixels
        img_gray = cv2.resize(img_gray, (32, 32))

        # Reshape to (32, 32, 1)
        img_gray = img_gray.reshape(32, 32, 1)

        # Make a prediction using the loaded model
        prediction = model.predict(np.expand_dims(img_gray, axis=0))

        # Determine the predicted label by selecting the class with the highest probability
        predicted_label = np.argmax(prediction, axis=1)

        # Map the class index to the corresponding label (e.g., 0 for non-bleeding, 1 for bleeding)
        if predicted_label == 0:
            label = "non-bleeding"
        else:
            label = "bleeding"

        # Append image name and predicted label to the lists
        image_names.append(image_file)
        predicted_labels.append(label)
    else:
        print(f"Image: {image_file}, Shape: Unable to read the image")

# Create a DataFrame to store the results
df = pd.DataFrame({'Image Name': image_names, 'Predicted Label': predicted_labels})

# Save the DataFrame to an Excel file
df.to_excel('/content/drive/MyDrive/test_2predictions.xlsx', index=False)

print("Predictions saved to predictions.xlsx")


--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#Using the saved model (CNN2d.h5), accurately predicting the image's label of Validation dataset and saving it to the Predicted_images
import os
import numpy as np
import cv2
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image

# Load the saved model
model = load_model('/content/drive/MyDrive/CNN2d.h5')  # Replace with the path to your saved model

# Define the image directories
image_directory = '/content/drive/MyDrive/final/WCEBleedGen/'

# Lists to store the file paths of predicted images, true labels, and predicted labels
predicted_images = []
true_labels = []
predicted_labels = []

# Process both bleeding and non-bleeding images
bleeding_directory = os.path.join(image_directory, 'bleeding/images')
non_bleeding_directory = os.path.join(image_directory, 'non-bleeding/images')

# Create a folder to save the predicted images
output_folder = '/content/drive/MyDrive/predicted_images'
os.makedirs(output_folder, exist_ok=True)

# Function to make predictions on an image and get the label
def predict_image(image_path):
    img = image.load_img(image_path, target_size=(32, 32), color_mode="grayscale")  # Load as grayscale
    img = image.img_to_array(img)
    img = np.expand_dims(img, axis=0)

    prediction = model.predict(img)
    predicted_label = np.argmax(prediction)
    label = "Bleeding" if predicted_label == 1 else "Non-Bleeding"

    return label

# Process images and make predictions
for image_name in os.listdir(bleeding_directory):
    if image_name.endswith('.png'):
        image_path = os.path.join(bleeding_directory, image_name)
        predicted_images.append(image_path)
        true_labels.append("Bleeding")
        predicted_labels.append(predict_image(image_path))

for image_name in os.listdir(non_bleeding_directory):
    if image_name.endswith('.png'):
        image_path = os.path.join(non_bleeding_directory, image_name)
        predicted_images.append(image_path)
        true_labels.append("Non-Bleeding")
        predicted_labels.append(predict_image(image_path))

# Combine images, true labels, and predicted labels
predictions = list(zip(predicted_images, true_labels, predicted_labels))

# Sort by prediction confidence
predictions.sort(key=lambda x: x[2] == "Bleeding", reverse=True)

# Save the 10 best-predicted images with labels to the output folder
for i, (image_path, true_label, predicted_label) in enumerate(predictions[:10]):
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    text = f"True Label: {true_label}, Predicted Label: {predicted_label}"

    # Add the text to the image
    img = cv2.putText(img, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)

    output_path = os.path.join(output_folder, f'predicted_{i+1}.png')
    cv2.imwrite(output_path, img)

print("Predicted images with labels saved to the output folder.")


--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#Using the saved model (CNN2d.h5), accurately predicting the image's label of Test Dataset 1  and saving it to the Predicted_test images
import cv2
import numpy as np
import random
import os
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model

# Load the saved model
model = load_model('/content/drive/MyDrive/CNN2d.h5')  # Replace with the path to your saved model

test_dataset_path = '/content/drive/MyDrive/test_dataset/Test Dataset 1/'

image_paths = [f for f in os.listdir(test_dataset_path) if f.endswith('.png')]

output_folder = '/content/drive/MyDrive/predicted_test_images'
os.makedirs(output_folder, exist_ok=True)

for i, image_path in enumerate(image_paths):
    # Load and preprocess the test image
    test_image_path = os.path.join(test_dataset_path, image_path)
    test_image = cv2.imread(test_image_path)
    test_image_rgb = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)  # Convert to RGB format for display

    # Make predictions using the model
    grayscale_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale
    grayscale_image = cv2.resize(grayscale_image, (32, 32))  # Resize to model's input size
    grayscale_image = np.expand_dims(grayscale_image, axis=0)  # Add batch dimension
    prediction = model.predict(grayscale_image)
    predicted_label = "Bleeding" if np.argmax(prediction) == 1 else "Non-Bleeding"

    # Save the predicted images in the output folder
    output_path = os.path.join(output_folder, f'predicted_{i+1}.png')
    cv2.imwrite(output_path, cv2.cvtColor(test_image_rgb, cv2.COLOR_RGB2BGR))
print("Predicted images saved to the output folder.")


----------------------------------------------------------------------------------------------------------------------------------------------------------------------
#Using the saved model (CNN2d.h5), accurately predicting the image's label of Test Dataset 2  and saving it to the Predicted_test_2_images

import cv2
import numpy as np
import random
import os
from tensorflow.keras.models import load_model

# Load the saved model
model = load_model('/content/drive/MyDrive/CNN2d.h5')  # Replace with the path to your saved model

# Path to the test dataset directory
test_dataset_path = '/content/drive/MyDrive/final/WCEBleedGen/non-bleeding/images/'

# Get a list of image file paths in the test dataset directory
image_paths = [f for f in os.listdir(test_dataset_path) if f.endswith('.png')]

# Select 5 random images from the list
random_image_paths = random.sample(image_paths, 10)

# Create a folder to save the predicted images
output_folder = '/content/drive/MyDrive/predicted_test_2_images'
os.makedirs(output_folder, exist_ok=True)

# Iterate over the randomly selected images
for i, image_path in enumerate(random_image_paths):
    # Load and preprocess the test image
    test_image_path = os.path.join(test_dataset_path, image_path)
    test_image = cv2.imread(test_image_path)
    test_image_rgb = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)  # Convert to RGB format for display

    # Make predictions using the model
    grayscale_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale
    grayscale_image = cv2.resize(grayscale_image, (32, 32))  # Resize to model's input size
    grayscale_image = np.expand_dims(grayscale_image, axis=0)  # Add batch dimension
    prediction = model.predict(grayscale_image)
    predicted_label = "Bleeding" if np.argmax(prediction) == 1 else "Non-Bleeding"



    # Save the predicted images with labels in the output folder
    output_path = os.path.join(output_folder, f'predicted_{i+1}_{predicted_label}.png')
    cv2.imwrite(output_path, cv2.cvtColor(test_image_rgb, cv2.COLOR_RGB2BGR))


--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#CAM plots for Validation and Test Dataset
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.densenet import preprocess_input, DenseNet121

# Load the DenseNet-121 model with pre-trained weights (excluding top classification layers)
base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Function to compute CAM for a specific class index
def compute_CAM(model, image_path, class_idx):
    # Load and preprocess the image
    img = image.load_img(image_path, target_size=(224, 224))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input(x)

    # Get the output of the final convolutional layer and the prediction
    final_conv_layer = model.get_layer('conv5_block16_concat')
    final_output_layer = model.get_layer('relu')

    # Create a model that extracts both the feature maps and predictions
    cam_model = Model(inputs=model.input, outputs=[final_conv_layer.output, final_output_layer.output])

    # Get feature maps and predictions
    features, preds = cam_model.predict(x)

    # Get the feature map for the class index
    class_activation_map = features[0, :, :, class_idx]

    # Normalize CAM
    cam = class_activation_map - np.min(class_activation_map)
    cam /= np.max(cam)

    # Resize CAM to match the image size
    cam = cv2.resize(cam, (224, 224))

    # Convert CAM to heatmap
    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)

    # Overlay heatmap on the original image
    img = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)
    superimposed_img = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)

    # Display the original image, CAM, and superimposed image
    plt.figure(figsize=(12, 4))
    plt.subplot(131)
    plt.imshow(img)
    plt.title('Original Image')

    plt.subplot(132)
    plt.imshow(cam, cmap='jet')
    plt.title('Class Activation Map (CAM)')

    plt.subplot(133)
    plt.imshow(superimposed_img)
    plt.title('CAM Superimposed')
    plt.show()

# Directory with bleeding images
bleeding_image_directory = '/content/drive/MyDrive/final/WCEBleedGen/bleeding/images/'

# Choose 5 random images
import random
random.seed(42)  # Set seed for reproducibility
selected_images = random.sample(os.listdir(bleeding_image_directory), 10)

# Compute and display CAM for the selected images
for image_name in selected_images:
    image_path = os.path.join(bleeding_image_directory, image_name)
    compute_CAM(base_model, image_path, class_idx=1)
--------------------------------------------------------------------------------------------------------------------------------------------------------------------
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.densenet import preprocess_input, DenseNet121

# Load the DenseNet-121 model with pre-trained weights (excluding top classification layers)
base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Function to compute CAM for a specific class index
def compute_CAM(model, image_path, class_idx):
    # Load and preprocess the image
    img = image.load_img(image_path, target_size=(224, 224))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input(x)

    # Get the output of the final convolutional layer and the prediction
    final_conv_layer = model.get_layer('conv5_block16_concat')
    final_output_layer = model.get_layer('relu')

    # Create a model that extracts both the feature maps and predictions
    cam_model = Model(inputs=model.input, outputs=[final_conv_layer.output, final_output_layer.output])

    # Get feature maps and predictions
    features, preds = cam_model.predict(x)

    # Get the feature map for the class index
    class_activation_map = features[0, :, :, class_idx]

    # Normalize CAM
    cam = class_activation_map - np.min(class_activation_map)
    cam /= np.max(cam)

    # Resize CAM to match the image size
    cam = cv2.resize(cam, (224, 224))

    # Convert CAM to heatmap
    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)

    # Overlay heatmap on the original image
    img = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)
    superimposed_img = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)

    # Display the original image, CAM, and superimposed image
    plt.figure(figsize=(12, 4))
    plt.subplot(131)
    plt.imshow(img)
    plt.title('Original Image')

    plt.subplot(132)
    plt.imshow(cam, cmap='jet')
    plt.title('Class Activation Map (CAM)')

    plt.subplot(133)
    plt.imshow(superimposed_img)
    plt.title('CAM Superimposed')
    plt.show()

# Directory with bleeding images
bleeding_image_directory = '/content/drive/MyDrive/test_dataset/Test Dataset 1/'

# Choose 5 random images
import random
random.seed(42)  # Set seed for reproducibility
selected_images = random.sample(os.listdir(bleeding_image_directory), 5)

# Compute and display CAM for the selected images
for image_name in selected_images:
    image_path = os.path.join(bleeding_image_directory, image_name)
    compute_CAM(base_model, image_path, class_idx=1)
--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#CAM plots for Validation and Test Dataset
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.densenet import preprocess_input, DenseNet121

# Load the DenseNet-121 model with pre-trained weights (excluding top classification layers)
base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Function to compute CAM for a specific class index
def compute_CAM(model, image_path, class_idx):
    # Load and preprocess the image
    img = image.load_img(image_path, target_size=(224, 224))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input(x)

    # Get the output of the final convolutional layer and the prediction
    final_conv_layer = model.get_layer('conv5_block16_concat')
    final_output_layer = model.get_layer('relu')

    # Create a model that extracts both the feature maps and predictions
    cam_model = Model(inputs=model.input, outputs=[final_conv_layer.output, final_output_layer.output])

    # Get feature maps and predictions
    features, preds = cam_model.predict(x)

    # Get the feature map for the class index
    class_activation_map = features[0, :, :, class_idx]

    # Normalize CAM
    cam = class_activation_map - np.min(class_activation_map)
    cam /= np.max(cam)

    # Resize CAM to match the image size
    cam = cv2.resize(cam, (224, 224))

    # Convert CAM to heatmap
    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)

    # Overlay heatmap on the original image
    img = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)
    superimposed_img = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)

    # Display the original image, CAM, and superimposed image
    plt.figure(figsize=(12, 4))
    plt.subplot(131)
    plt.imshow(img)
    plt.title('Original Image')

    plt.subplot(132)
    plt.imshow(cam, cmap='jet')
    plt.title('Class Activation Map (CAM)')

    plt.subplot(133)
    plt.imshow(superimposed_img)
    plt.title('CAM Superimposed')
    plt.show()

# Directory with bleeding images
bleeding_image_directory = '/content/drive/MyDrive/test_dataset/Test Dataset 2/'

# Choose 5 random images
import random
random.seed(42)  # Set seed for reproducibility
selected_images = random.sample(os.listdir(bleeding_image_directory), 5)

# Compute and display CAM for the selected images
for image_name in selected_images:
    image_path = os.path.join(bleeding_image_directory, image_name)
    compute_CAM(base_model, image_path, class_idx=1)
print("Predicted images with labels saved to the output folder.")


